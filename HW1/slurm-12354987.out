2025-09-29 23:14:42.815274: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-29 23:14:43.436584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14618 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:3b:00.0, compute capability: 7.5
2025-09-29 23:14:44.039753: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)

=== A_lr_0.001_drop_0.0_l2_0.0 ===
arch=[256, 128] lr=0.001 dropout=0.0 l2=0.0 epochs=10
Epoch 1/10
1688/1688 - 8s - loss: 0.8319 - accuracy: 0.6965 - val_loss: 0.5769 - val_accuracy: 0.7868
Epoch 2/10
1688/1688 - 5s - loss: 0.5453 - accuracy: 0.8031 - val_loss: 0.5057 - val_accuracy: 0.8180
Epoch 3/10
1688/1688 - 5s - loss: 0.4851 - accuracy: 0.8263 - val_loss: 0.4570 - val_accuracy: 0.8325
Epoch 4/10
1688/1688 - 5s - loss: 0.4481 - accuracy: 0.8411 - val_loss: 0.4359 - val_accuracy: 0.8383
Epoch 5/10
1688/1688 - 5s - loss: 0.4235 - accuracy: 0.8480 - val_loss: 0.4220 - val_accuracy: 0.8437
Epoch 6/10
1688/1688 - 5s - loss: 0.4065 - accuracy: 0.8524 - val_loss: 0.4073 - val_accuracy: 0.8523
Epoch 7/10
1688/1688 - 5s - loss: 0.3906 - accuracy: 0.8598 - val_loss: 0.3838 - val_accuracy: 0.8590
Epoch 8/10
1688/1688 - 5s - loss: 0.3779 - accuracy: 0.8636 - val_loss: 0.3769 - val_accuracy: 0.8625
Epoch 9/10
1688/1688 - 5s - loss: 0.3682 - accuracy: 0.8664 - val_loss: 0.3687 - val_accuracy: 0.8637
Epoch 10/10
1688/1688 - 5s - loss: 0.3574 - accuracy: 0.8715 - val_loss: 0.3653 - val_accuracy: 0.8658
VAL  -> loss=0.3653  acc=0.8658
TEST -> loss=0.3981 acc=0.8556
Test Confusion Matrix (rows=true, cols=pred):
[[813   5   6  58   9   2  98   0   9   0]
 [  0 961   2  28   6   0   2   0   1   0]
 [ 11   0 723  22 182   0  62   0   0   0]
 [ 21  13   5 886  49   1  23   0   2   0]
 [  0   2  73  25 865   0  35   0   0   0]
 [  0   0   0   1   0 932   0  33   5  29]
 [146   1 104  50 146   1 542   0  10   0]
 [  0   0   0   0   0  38   0 910   0  52]
 [  1   1   2   6   7   3  13   3 964   0]
 [  0   0   0   1   0   8   1  30   0 960]]

=== A_lr_0.001_drop_0.2_l2_0.0001 ===
arch=[256, 128] lr=0.001 dropout=0.2 l2=0.0001 epochs=10
Epoch 1/10
1688/1688 - 5s - loss: 1.0877 - accuracy: 0.6451 - val_loss: 0.7964 - val_accuracy: 0.7518
Epoch 2/10
1688/1688 - 5s - loss: 0.8069 - accuracy: 0.7598 - val_loss: 0.7139 - val_accuracy: 0.7913
Epoch 3/10
1688/1688 - 5s - loss: 0.7466 - accuracy: 0.7839 - val_loss: 0.6953 - val_accuracy: 0.8008
Epoch 4/10
1688/1688 - 5s - loss: 0.7089 - accuracy: 0.7979 - val_loss: 0.6421 - val_accuracy: 0.8208
Epoch 5/10
1688/1688 - 5s - loss: 0.6821 - accuracy: 0.8058 - val_loss: 0.6222 - val_accuracy: 0.8268
Epoch 6/10
1688/1688 - 5s - loss: 0.6612 - accuracy: 0.8125 - val_loss: 0.6087 - val_accuracy: 0.8295
Epoch 7/10
1688/1688 - 5s - loss: 0.6447 - accuracy: 0.8178 - val_loss: 0.5923 - val_accuracy: 0.8335
Epoch 8/10
1688/1688 - 5s - loss: 0.6310 - accuracy: 0.8202 - val_loss: 0.5863 - val_accuracy: 0.8358
Epoch 9/10
1688/1688 - 5s - loss: 0.6187 - accuracy: 0.8236 - val_loss: 0.5851 - val_accuracy: 0.8365
Epoch 10/10
1688/1688 - 5s - loss: 0.6100 - accuracy: 0.8280 - val_loss: 0.5641 - val_accuracy: 0.8438
VAL  -> loss=0.5641  acc=0.8438
TEST -> loss=0.5915 acc=0.8343
Test Confusion Matrix (rows=true, cols=pred):
[[864   1   9  23   5   2  78   0  18   0]
 [  9 942  12  30   4   0   2   0   1   0]
 [ 24   0 777   7 107   0  78   0   7   0]
 [ 65  10   9 797  48   0  66   0   5   0]
 [  0   1 144  23 722   0 104   0   6   0]
 [  0   0   0   1   0 915   0  60   8  16]
 [208   2 131  17  80   1 535   0  26   0]
 [  0   0   0   0   0  40   0 931   0  29]
 [  1   1   9   3   2   4  17   5 958   0]
 [  0   0   0   1   0  32   0  64   1 902]]

=== A_lr_0.0003_drop_0.0_l2_0.0 ===
arch=[256, 128] lr=0.0003 dropout=0.0 l2=0.0 epochs=10
Epoch 1/10
1688/1688 - 5s - loss: 1.1045 - accuracy: 0.6233 - val_loss: 0.7193 - val_accuracy: 0.7393
Epoch 2/10
1688/1688 - 5s - loss: 0.6601 - accuracy: 0.7564 - val_loss: 0.6108 - val_accuracy: 0.7727
Epoch 3/10
1688/1688 - 5s - loss: 0.5856 - accuracy: 0.7861 - val_loss: 0.5552 - val_accuracy: 0.7987
Epoch 4/10
1688/1688 - 5s - loss: 0.5415 - accuracy: 0.8062 - val_loss: 0.5208 - val_accuracy: 0.8160
Epoch 5/10
1688/1688 - 5s - loss: 0.5090 - accuracy: 0.8192 - val_loss: 0.4885 - val_accuracy: 0.8285
Epoch 6/10
1688/1688 - 5s - loss: 0.4835 - accuracy: 0.8286 - val_loss: 0.4712 - val_accuracy: 0.8338
Epoch 7/10
1688/1688 - 5s - loss: 0.4647 - accuracy: 0.8351 - val_loss: 0.4591 - val_accuracy: 0.8363
Epoch 8/10
1688/1688 - 5s - loss: 0.4491 - accuracy: 0.8402 - val_loss: 0.4492 - val_accuracy: 0.8380
Epoch 9/10
1688/1688 - 5s - loss: 0.4371 - accuracy: 0.8445 - val_loss: 0.4378 - val_accuracy: 0.8398
Epoch 10/10
1688/1688 - 5s - loss: 0.4270 - accuracy: 0.8478 - val_loss: 0.4227 - val_accuracy: 0.8468
VAL  -> loss=0.4227  acc=0.8468
TEST -> loss=0.4569 acc=0.8355
Test Confusion Matrix (rows=true, cols=pred):
[[838   1  15  58   5   4  66   0  13   0]
 [  1 949   8  32   6   0   3   0   1   0]
 [ 23   1 744  14 155   0  59   0   4   0]
 [ 29  11  11 867  40   0  37   0   5   0]
 [  0   0 109  34 781   0  71   0   5   0]
 [  0   0   0   1   0 908   0  52   6  33]
 [180   2 135  49 135   2 471   0  26   0]
 [  0   0   0   0   0  43   0 904   0  53]
 [  2   1   8  11   3   5  12   5 953   0]
 [  0   0   0   0   0  20   0  38   2 940]]

=== A_lr_0.0003_drop_0.2_l2_0.0001 ===
arch=[256, 128] lr=0.0003 dropout=0.2 l2=0.0001 epochs=10
Epoch 1/10
1688/1688 - 5s - loss: 1.3373 - accuracy: 0.5543 - val_loss: 0.9764 - val_accuracy: 0.7072
Epoch 2/10
1688/1688 - 5s - loss: 0.9496 - accuracy: 0.7062 - val_loss: 0.8387 - val_accuracy: 0.7430
Epoch 3/10
1688/1688 - 5s - loss: 0.8570 - accuracy: 0.7392 - val_loss: 0.7829 - val_accuracy: 0.7648
Epoch 4/10
1688/1688 - 5s - loss: 0.8113 - accuracy: 0.7566 - val_loss: 0.7457 - val_accuracy: 0.7778
Epoch 5/10
1688/1688 - 5s - loss: 0.7786 - accuracy: 0.7713 - val_loss: 0.7214 - val_accuracy: 0.7902
Epoch 6/10
1688/1688 - 5s - loss: 0.7551 - accuracy: 0.7794 - val_loss: 0.7123 - val_accuracy: 0.7987
Epoch 7/10
1688/1688 - 5s - loss: 0.7352 - accuracy: 0.7875 - val_loss: 0.6850 - val_accuracy: 0.8048
Epoch 8/10
1688/1688 - 5s - loss: 0.7179 - accuracy: 0.7951 - val_loss: 0.6750 - val_accuracy: 0.8097
Epoch 9/10
1688/1688 - 5s - loss: 0.7018 - accuracy: 0.8010 - val_loss: 0.6614 - val_accuracy: 0.8188
Epoch 10/10
1688/1688 - 5s - loss: 0.6873 - accuracy: 0.8058 - val_loss: 0.6481 - val_accuracy: 0.8187
VAL  -> loss=0.6481  acc=0.8187
TEST -> loss=0.6694 acc=0.8084
Test Confusion Matrix (rows=true, cols=pred):
[[794   4   6  97   3   4  78   0  14   0]
 [  0 932  13  50   3   0   1   0   1   0]
 [ 20   2 658  15 166   1 132   0   6   0]
 [ 35   8   3 884  21   1  45   0   2   1]
 [  0   1 103  57 728   0 106   0   5   0]
 [  0   0   0   1   0 871   0  79   4  45]
 [200   2 110  78 120   2 461   0  27   0]
 [  0   0   0   0   0  37   0 904   0  59]
 [  0   1   3  14   1  15  32   5 926   3]
 [  0   0   0   0   0  22   0  51   1 926]]

=== B_lr_0.001_drop_0.0_l2_0.0 ===
arch=[512, 256, 128] lr=0.001 dropout=0.0 l2=0.0 epochs=10
Epoch 1/10
1688/1688 - 6s - loss: 0.7414 - accuracy: 0.7219 - val_loss: 0.5131 - val_accuracy: 0.8072
Epoch 2/10
1688/1688 - 5s - loss: 0.4798 - accuracy: 0.8240 - val_loss: 0.4316 - val_accuracy: 0.8422
Epoch 3/10
1688/1688 - 5s - loss: 0.4179 - accuracy: 0.8453 - val_loss: 0.3922 - val_accuracy: 0.8578
Epoch 4/10
1688/1688 - 5s - loss: 0.3832 - accuracy: 0.8581 - val_loss: 0.3717 - val_accuracy: 0.8637
Epoch 5/10
1688/1688 - 5s - loss: 0.3616 - accuracy: 0.8660 - val_loss: 0.3432 - val_accuracy: 0.8723
Epoch 6/10
1688/1688 - 5s - loss: 0.3442 - accuracy: 0.8725 - val_loss: 0.3454 - val_accuracy: 0.8725
Epoch 7/10
1688/1688 - 5s - loss: 0.3298 - accuracy: 0.8780 - val_loss: 0.3716 - val_accuracy: 0.8643
Epoch 8/10
1688/1688 - 5s - loss: 0.3173 - accuracy: 0.8826 - val_loss: 0.3341 - val_accuracy: 0.8785
Epoch 9/10
1688/1688 - 5s - loss: 0.3062 - accuracy: 0.8864 - val_loss: 0.3185 - val_accuracy: 0.8833
Epoch 10/10
1688/1688 - 5s - loss: 0.2977 - accuracy: 0.8894 - val_loss: 0.3316 - val_accuracy: 0.8763
VAL  -> loss=0.3316  acc=0.8763
TEST -> loss=0.3694 acc=0.8677
Test Confusion Matrix (rows=true, cols=pred):
[[885   1  12  63   5   2  24   0   8   0]
 [  4 950   1  39   3   0   2   0   1   0]
 [ 20   0 834  24  96   0  23   0   3   0]
 [ 17   2   7 923  35   0  10   0   6   0]
 [  0   1 121  33 829   0  15   0   1   0]
 [  0   0   0   0   0 933   1  49   3  14]
 [214   1 135  66 119   0 450   0  15   0]
 [  0   0   0   0   0  14   0 938   1  47]
 [  1   0   1   6   4   3   1   3 981   0]
 [  0   0   0   0   0  19   1  26   0 954]]

=== B_lr_0.001_drop_0.2_l2_0.0001 ===
arch=[512, 256, 128] lr=0.001 dropout=0.2 l2=0.0001 epochs=10
Epoch 1/10
1688/1688 - 6s - loss: 0.9710 - accuracy: 0.6686 - val_loss: 0.6726 - val_accuracy: 0.7933
Epoch 2/10
1688/1688 - 6s - loss: 0.7108 - accuracy: 0.7862 - val_loss: 0.6174 - val_accuracy: 0.8233
Epoch 3/10
1688/1688 - 6s - loss: 0.6612 - accuracy: 0.8082 - val_loss: 0.6003 - val_accuracy: 0.8312
Epoch 4/10
1688/1688 - 6s - loss: 0.6340 - accuracy: 0.8188 - val_loss: 0.5733 - val_accuracy: 0.8380
Epoch 5/10
1688/1688 - 6s - loss: 0.6114 - accuracy: 0.8264 - val_loss: 0.5674 - val_accuracy: 0.8425
Epoch 6/10
1688/1688 - 6s - loss: 0.5981 - accuracy: 0.8296 - val_loss: 0.5528 - val_accuracy: 0.8442
Epoch 7/10
1688/1688 - 6s - loss: 0.5890 - accuracy: 0.8323 - val_loss: 0.5880 - val_accuracy: 0.8235
Epoch 8/10
1688/1688 - 6s - loss: 0.5761 - accuracy: 0.8369 - val_loss: 0.5547 - val_accuracy: 0.8378
Epoch 9/10
1688/1688 - 6s - loss: 0.5666 - accuracy: 0.8395 - val_loss: 0.5149 - val_accuracy: 0.8553
Epoch 10/10
1688/1688 - 6s - loss: 0.5639 - accuracy: 0.8387 - val_loss: 0.5323 - val_accuracy: 0.8460
VAL  -> loss=0.5323  acc=0.8460
TEST -> loss=0.5684 acc=0.8383
Test Confusion Matrix (rows=true, cols=pred):
[[841   1  16  23   5   6 102   0   6   0]
 [  2 964   7  22   3   0   1   0   1   0]
 [ 24   1 867   4  57   1  45   0   1   0]
 [ 44  14  10 812  64   2  53   0   1   0]
 [  0   1 232  12 698   0  55   0   2   0]
 [  0   1   0   0   0 949   0  32   1  17]
 [180   2 185  15  78   3 526   0  11   0]
 [  0   0   0   0   0  49   0 892   0  59]
 [  2   1  13   3   6  26  44   5 899   1]
 [  0   0   0   0   0  37   0  27   1 935]]

=== B_lr_0.0003_drop_0.0_l2_0.0 ===
arch=[512, 256, 128] lr=0.0003 dropout=0.0 l2=0.0 epochs=10
Epoch 1/10
1688/1688 - 6s - loss: 0.8913 - accuracy: 0.6816 - val_loss: 0.6369 - val_accuracy: 0.7617
Epoch 2/10
1688/1688 - 5s - loss: 0.5809 - accuracy: 0.7853 - val_loss: 0.5262 - val_accuracy: 0.8048
Epoch 3/10
1688/1688 - 5s - loss: 0.5073 - accuracy: 0.8156 - val_loss: 0.4795 - val_accuracy: 0.8215
Epoch 4/10
1688/1688 - 5s - loss: 0.4634 - accuracy: 0.8316 - val_loss: 0.4481 - val_accuracy: 0.8340
Epoch 5/10
1688/1688 - 5s - loss: 0.4352 - accuracy: 0.8422 - val_loss: 0.4494 - val_accuracy: 0.8350
Epoch 6/10
1688/1688 - 5s - loss: 0.4153 - accuracy: 0.8490 - val_loss: 0.4046 - val_accuracy: 0.8542
Epoch 7/10
1688/1688 - 5s - loss: 0.3988 - accuracy: 0.8559 - val_loss: 0.3890 - val_accuracy: 0.8563
Epoch 8/10
1688/1688 - 5s - loss: 0.3843 - accuracy: 0.8598 - val_loss: 0.3834 - val_accuracy: 0.8588
Epoch 9/10
1688/1688 - 5s - loss: 0.3703 - accuracy: 0.8657 - val_loss: 0.3685 - val_accuracy: 0.8615
Epoch 10/10
1688/1688 - 5s - loss: 0.3578 - accuracy: 0.8691 - val_loss: 0.3646 - val_accuracy: 0.8653
VAL  -> loss=0.3646  acc=0.8653
TEST -> loss=0.4005 acc=0.8561
Test Confusion Matrix (rows=true, cols=pred):
[[873   0  13  29   2   3  67   0  13   0]
 [  6 942   7  36   4   0   4   0   1   0]
 [ 24   0 835  10  71   0  57   0   3   0]
 [ 44   7  11 862  36   0  35   0   5   0]
 [  0   1 183  32 709   0  73   0   2   0]
 [  0   0   0   1   0 942   0  29   5  23]
 [190   1 145  26  66   0 556   0  16   0]
 [  0   0   0   0   0  37   0 916   0  47]
 [  1   1   3   3   3   4   9   4 972   0]
 [  0   0   0   0   0  14   1  31   0 954]]

=== B_lr_0.0003_drop_0.2_l2_0.0001 ===
arch=[512, 256, 128] lr=0.0003 dropout=0.2 l2=0.0001 epochs=10
Epoch 1/10
1688/1688 - 6s - loss: 1.1389 - accuracy: 0.6033 - val_loss: 0.7877 - val_accuracy: 0.7363
Epoch 2/10
1688/1688 - 6s - loss: 0.7861 - accuracy: 0.7516 - val_loss: 0.6859 - val_accuracy: 0.7983
Epoch 3/10
1688/1688 - 6s - loss: 0.7090 - accuracy: 0.7863 - val_loss: 0.6377 - val_accuracy: 0.8087
Epoch 4/10
1688/1688 - 6s - loss: 0.6674 - accuracy: 0.8025 - val_loss: 0.6157 - val_accuracy: 0.8207
Epoch 5/10
1688/1688 - 6s - loss: 0.6359 - accuracy: 0.8139 - val_loss: 0.5911 - val_accuracy: 0.8305
Epoch 6/10
1688/1688 - 6s - loss: 0.6167 - accuracy: 0.8215 - val_loss: 0.5766 - val_accuracy: 0.8323
Epoch 7/10
1688/1688 - 6s - loss: 0.5968 - accuracy: 0.8291 - val_loss: 0.5662 - val_accuracy: 0.8320
Epoch 8/10
1688/1688 - 6s - loss: 0.5855 - accuracy: 0.8328 - val_loss: 0.5359 - val_accuracy: 0.8463
Epoch 9/10
1688/1688 - 6s - loss: 0.5691 - accuracy: 0.8381 - val_loss: 0.5471 - val_accuracy: 0.8415
Epoch 10/10
1688/1688 - 6s - loss: 0.5581 - accuracy: 0.8421 - val_loss: 0.5209 - val_accuracy: 0.8510
VAL  -> loss=0.5209  acc=0.8510
TEST -> loss=0.5567 acc=0.8402
Test Confusion Matrix (rows=true, cols=pred):
[[760   1  13  52   8   4 152   0  10   0]
 [  0 941   7  43   5   0   2   0   2   0]
 [ 10   0 761  12 145   0  70   0   2   0]
 [ 24   6   6 834  77   1  46   0   6   0]
 [  0   0 104  17 816   0  61   0   2   0]
 [  0   0   0   1   0 913   0  55   5  26]
 [122   1 133  37 119   2 574   0  12   0]
 [  0   0   0   0   0  33   0 945   0  22]
 [  0   1   6   3   6   9  33   4 937   1]
 [  0   0   0   0   0  23   0  55   1 921]]
